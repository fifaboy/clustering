{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, timeit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from metrics import process\n",
    "\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "from kmeans_clustering import KMeansClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "data_dir = join(pwd, 'data/')\n",
    "need_normalization = True\n",
    "need_standardization = False\n",
    "need_pca = False\n",
    "filename = 'iris.csv'\n",
    "datapath = join(data_dir, filename)\n",
    "num_clusters = 5\n",
    "num_iterations = 300\n",
    "num_iter_exp = 20\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('data/data.csv')\n",
    "# lines = f.read()\n",
    "# print(type(lines))\n",
    "# new_lines = ''\n",
    "# for line in lines:\n",
    "#     new_lines += str(line.encode('utf-8').strip())\n",
    "# print(len(new_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    datapath, \n",
    "    low_memory=False,\n",
    "    encoding='utf-8',\n",
    "#     sep=',',\n",
    "    header=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0            1             2            3        4\n",
      "0  sepal.length  sepal.width  petal.length  petal.width  variety\n",
      "1           5.1          3.5           1.4           .2   Setosa\n",
      "2           4.9            3           1.4           .2   Setosa\n",
      "3           4.7          3.2           1.3           .2   Setosa\n",
      "4           4.6          3.1           1.5           .2   Setosa\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    object\n",
      "1    object\n",
      "2    object\n",
      "3    object\n",
      "4    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "0    float64\n",
      "1    float64\n",
      "2    float64\n",
      "3    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns.tolist()\n",
    "cols = columns\n",
    "# cols = columns[1:]\n",
    "# cols = ['Survived', 'Pclass', 'Age', 'SibSp', 'Fare']\n",
    "cols = columns[:-1]\n",
    "# cols = ['Passenger Count', 'Adjusted Passenger Count']\n",
    "# cols = columns[1:]\n",
    "# cols = columns[2:]\n",
    "df = df[cols]\n",
    "for col in cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "df = df.fillna(0)\n",
    "df = df.replace([-np.inf, np.inf], np.nan)\n",
    "df = df.dropna()\n",
    "df = df.loc[:, (df != 0).any(axis=0)]\n",
    "print(len(df))\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(\n",
    "    frac=1.0,\n",
    "    random_state=1,\n",
    ")\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if need_normalization is True:\n",
    "    normalizer = StandardScaler()\n",
    "    tmp = normalizer.fit_transform(df)\n",
    "    df = pd.DataFrame(tmp, columns=df.columns)\n",
    "elif need_standardization is True:\n",
    "    scaler = MinMaxScaler()\n",
    "    tmp = scaler.fit_transform(df)\n",
    "    df = pd.DataFrame(tmp, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "if need_pca is True:\n",
    "    pca = PCA(\n",
    "        n_components=len(cols),\n",
    "        svd_solver='auto',\n",
    "    )\n",
    "    X = pca.fit_transform(X)\n",
    "else:\n",
    "    X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in X:\n",
    "    for a in x:\n",
    "        if np.isinf(a):\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.58493671 -0.07432758 -1.47939109 -1.42965201]\n",
      " [ 0.41646444 -0.2747466   0.3185007   0.1422712 ]\n",
      " [ 0.62713825 -0.2747466   0.3185007   0.1422712 ]\n",
      " [-0.11022007  2.73153862 -1.25465462 -1.03667121]\n",
      " [ 1.68050728 -0.47516561  1.32981483  0.9282328 ]]\n",
      "(151, 4)\n"
     ]
    }
   ],
   "source": [
    "data = X\n",
    "print(data[:5])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['coc', 'kmeans++', 'variance', 'ostrovsky']\n",
    "# models = ['kmeans++', 'kmeans++_corrected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(X, labels):\n",
    "    fig, ax = plt.subplots()\n",
    "    scatter = plt.scatter(\n",
    "        X[:, 0],\n",
    "        X[:, 1],\n",
    "        c=labels,\n",
    "    )\n",
    "    handles, labels = scatter.legend_elements()\n",
    "    legend = ax.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        loc='upper right',\n",
    "        title='Label',\n",
    "    )\n",
    "    ax.add_artist(legend)\n",
    "    plt.title(model+' '+str(num_clusters)+ ' clusters')\n",
    "    plt.xlabel('Component A')\n",
    "    plt.ylabel('Component B')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:00<00:00,  3.05s/it]\n"
     ]
    }
   ],
   "source": [
    "algorithms = {}\n",
    "iterations = {}\n",
    "inertias = {}\n",
    "times = {}\n",
    "inertias_min = {}\n",
    "iters_min = {}\n",
    "for model in models:\n",
    "    iterations[model] = 0.0\n",
    "    inertias[model] = 0.0\n",
    "    times[model] = 0.0\n",
    "    iters_min[model] = 0\n",
    "    inertias_min[model] = 1e20\n",
    "for i in tqdm(range(num_iter_exp)):\n",
    "    for model in (models):\n",
    "        algorithms[model] = KMeansClustering(\n",
    "            n_clusters=num_clusters,\n",
    "            max_iter=num_iterations,\n",
    "            init=model,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        start = timeit.default_timer()\n",
    "        algorithm = algorithms[model].fit(data)\n",
    "        centers = algorithm.cluster_centers_\n",
    "        labels = algorithms[model].predict(data)\n",
    "#         plot_scatter(X, labels)\n",
    "        inertias[model] += algorithm.best_inertia_\n",
    "        inertias_min[model] = min(inertias_min[model], algorithm.best_inertia_)\n",
    "        iters_min[model] += algorithm.n_iters_\n",
    "        end = timeit.default_timer()\n",
    "        times[model] += (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coc, 5\n",
      "Average Inertia - 105.44\n",
      "Minimum Inertia -  91.82\n",
      "Time - 0.76\n",
      "\n",
      "kmeans++, 5\n",
      "Average Inertia - 107.65\n",
      "Minimum Inertia -  91.82\n",
      "Time - 0.76\n",
      "\n",
      "variance, 5\n",
      "Average Inertia - 99.53\n",
      "Minimum Inertia -  91.82\n",
      "Time - 0.77\n",
      "\n",
      "ostrovsky, 5\n",
      "Average Inertia - 101.5\n",
      "Minimum Inertia -  91.82\n",
      "Time - 0.76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model+', '+str(num_clusters))\n",
    "    print('Average Inertia -', round(inertias[model]/num_iter_exp, 2))\n",
    "    print('Minimum Inertia - ', round(inertias_min[model], 2))\n",
    "    print('Time -', round(times[model]/num_iter_exp, 2))\n",
    "#     print('Average number of iterations', round(iters_min[model]/num_iter_exp,2))\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, timeit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from metrics import process\n",
    "\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "from kmeans_clustering import KMeansClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "data_dir = join(pwd, 'data/')\n",
    "need_normalization = False\n",
    "need_standardization = False\n",
    "need_pca = True\n",
    "filename = 'cancer.csv'\n",
    "datapath = join(data_dir, filename)\n",
    "num_clusters = 5\n",
    "num_iterations = 300\n",
    "num_iter_exp = 20\n",
    "verbose = False\n",
    "data_boston = load_boston()\n",
    "do_boston = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('data/data.csv')\n",
    "# lines = f.read()\n",
    "# print(type(lines))\n",
    "# new_lines = ''\n",
    "# for line in lines:\n",
    "#     new_lines += str(line.encode('utf-8').strip())\n",
    "# print(len(new_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    datapath, \n",
    "    low_memory=False,\n",
    "    encoding='utf-8',\n",
    "#     sep=',',\n",
    "#     header=None,\n",
    ")\n",
    "if do_boston is True:\n",
    "    df = pd.DataFrame(\n",
    "        data_boston.data, \n",
    "        columns=data_boston.feature_names,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Complete TCGA ID  Gender  Age at Initial Pathologic Diagnosis ER Status  \\\n",
      "0     TCGA-A2-A0T2  FEMALE                                   66  Negative   \n",
      "1     TCGA-A2-A0CM  FEMALE                                   40  Negative   \n",
      "2     TCGA-BH-A18V  FEMALE                                   48  Negative   \n",
      "3     TCGA-BH-A18Q  FEMALE                                   56  Negative   \n",
      "4     TCGA-BH-A0E0  FEMALE                                   38  Negative   \n",
      "\n",
      "  PR Status HER2 Final Status Tumor Tumor--T1 Coded Node Node-Coded  ...  \\\n",
      "0  Negative          Negative    T3         T_Other   N3   Positive  ...   \n",
      "1  Negative          Negative    T2         T_Other   N0   Negative  ...   \n",
      "2  Negative          Negative    T2         T_Other   N1   Positive  ...   \n",
      "3  Negative          Negative    T2         T_Other   N1   Positive  ...   \n",
      "4  Negative          Negative    T3         T_Other   N3   Positive  ...   \n",
      "\n",
      "   PAM50 mRNA SigClust Unsupervised mRNA SigClust Intrinsic mRNA  \\\n",
      "0  Basal-like                          0                     -13   \n",
      "1  Basal-like                        -12                     -13   \n",
      "2  Basal-like                        -12                     -13   \n",
      "3  Basal-like                        -12                     -13   \n",
      "4  Basal-like                          0                     -13   \n",
      "\n",
      "  miRNA Clusters methylation Clusters RPPA Clusters  CN Clusters  \\\n",
      "0              3                    5         Basal            3   \n",
      "1              4                    4         Basal            4   \n",
      "2              5                    5         Basal            1   \n",
      "3              5                    5         Basal            1   \n",
      "4              5                    5         Basal            1   \n",
      "\n",
      "   Integrated Clusters (with PAM50)  Integrated Clusters (no exp)  \\\n",
      "0                                 2                             2   \n",
      "1                                 2                             1   \n",
      "2                                 2                             2   \n",
      "3                                 2                             2   \n",
      "4                                 2                             2   \n",
      "\n",
      "   Integrated Clusters (unsup exp)  \n",
      "0                                2  \n",
      "1                                1  \n",
      "2                                2  \n",
      "3                                2  \n",
      "4                                2  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eruptions    float64\n",
      "waiting        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n",
      "eruptions    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns.tolist()\n",
    "cols = columns\n",
    "# cols = columns[1:]\n",
    "# cols = ['Survived', 'Pclass', 'Age', 'SibSp', 'Fare']\n",
    "cols = columns[:-1]\n",
    "# cols = ['Passenger Count', 'Adjusted Passenger Count']\n",
    "# cols = columns[1:]\n",
    "# cols = columns[2:]\n",
    "df = df[cols]\n",
    "for col in cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "df = df.fillna(0)\n",
    "df = df.replace([-np.inf, np.inf], np.nan)\n",
    "df = df.dropna()\n",
    "df = df.loc[:, (df != 0).any(axis=0)]\n",
    "print(len(df))\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(\n",
    "    frac=1.0,\n",
    "    random_state=1,\n",
    ")\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if need_normalization is True:\n",
    "    normalizer = StandardScaler()\n",
    "    tmp = normalizer.fit_transform(df)\n",
    "    df = pd.DataFrame(tmp, columns=df.columns)\n",
    "elif need_standardization is True:\n",
    "    scaler = MinMaxScaler()\n",
    "    tmp = scaler.fit_transform(df)\n",
    "    df = pd.DataFrame(tmp, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "if need_pca is True:\n",
    "    pca = PCA(\n",
    "        n_components=len(cols),\n",
    "        svd_solver='auto',\n",
    "    )\n",
    "    X = pca.fit_transform(X)\n",
    "else:\n",
    "    X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in X:\n",
    "    for a in x:\n",
    "        if np.isinf(a):\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07078309]\n",
      " [-0.11221691]\n",
      " [ 1.07078309]\n",
      " [-1.24521691]\n",
      " [-0.42921691]]\n",
      "(272, 1)\n"
     ]
    }
   ],
   "source": [
    "data = X\n",
    "print(data[:5])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['coc', 'kmeans++', 'ostrovsky', 'kmeans']\n",
    "models = ['kmeans++', 'kmeans++_improved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(X, labels):\n",
    "    fig, ax = plt.subplots()\n",
    "    scatter = plt.scatter(\n",
    "        X[:, 0],\n",
    "        X[:, 1],\n",
    "        c=labels,\n",
    "    )\n",
    "    handles, labels = scatter.legend_elements()\n",
    "    legend = ax.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        loc='upper right',\n",
    "        title='Label',\n",
    "    )\n",
    "    ax.add_artist(legend)\n",
    "    plt.title(model+' '+str(num_clusters)+ ' clusters')\n",
    "    plt.xlabel('Component A')\n",
    "    plt.ylabel('Component B')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]\n"
     ]
    }
   ],
   "source": [
    "algorithms = {}\n",
    "iterations = {}\n",
    "inertias = {}\n",
    "times = {}\n",
    "inertias_min = {}\n",
    "iters_min = {}\n",
    "for model in models:\n",
    "    iterations[model] = 0.0\n",
    "    inertias[model] = 0.0\n",
    "    times[model] = 0.0\n",
    "    iters_min[model] = 0\n",
    "    inertias_min[model] = 1e20\n",
    "for i in tqdm(range(num_iter_exp)):\n",
    "    for model in (models):\n",
    "        algorithms[model] = KMeansClustering(\n",
    "            n_clusters=num_clusters,\n",
    "            max_iter=num_iterations,\n",
    "            init=model,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        start = timeit.default_timer()\n",
    "        algorithm = algorithms[model].fit(data)\n",
    "        centers = algorithm.cluster_centers_\n",
    "        labels = algorithms[model].predict(data)\n",
    "#         plot_scatter(X, labels)\n",
    "        inertias[model] += algorithm.sse_\n",
    "        inertias_min[model] = min(inertias_min[model], algorithm.sse_)\n",
    "        iters_min[model] += algorithm.iter_convergence_\n",
    "        end = timeit.default_timer()\n",
    "        times[model] += (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans++, 5\n",
      "Average Inertia - 7.66\n",
      "Minimum Inertia -  7.0\n",
      "Time - 0.91\n",
      "\n",
      "kmeans++_improved, 5\n",
      "Average Inertia - 7.55\n",
      "Minimum Inertia -  7.0\n",
      "Time - 0.91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model+', '+str(num_clusters))\n",
    "    print('Average Inertia -', round(inertias[model]/num_iter_exp, 2))\n",
    "    print('Minimum Inertia - ', round(inertias_min[model], 2))\n",
    "    print('Time -', round(times[model]/num_iter_exp, 2))\n",
    "#     print('Average number of iterations', round(iters_min[model]/num_iter_exp,2))\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
